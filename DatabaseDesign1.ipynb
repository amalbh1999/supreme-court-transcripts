{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supreme Court Transcripts Database Design**\n",
    "\n",
    "### Contents:\n",
    " 1. Finding Justices Present\n",
    " 2. Date, Year\n",
    " 3. Appearances\n",
    " 4. Sentiment Analysis \n",
    " 5. Building the DataFrame\n",
    " \n",
    "## Note to Everyone: Make sure you've uploaded the textfiles from this folder: https://drive.google.com/drive/folders/1aepNIVRUS0rwu-m_fqK7KnWEqhyJFBvW my directory might be different from yours so make sure to check !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "\n",
    "# Read in a plain text file\n",
    "files = []\n",
    "for i in os.listdir('/home/jovyan/Liberating Archives Project'):\n",
    "    if i.endswith('.txt'):\n",
    "        text = open(i).read()\n",
    "        files.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='SEC v. Zandford.pdf.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "for txt in files:\n",
    "    clean = re.sub('\\xad','',txt)\n",
    "    clean = re.sub('\\n','',clean)\n",
    "    clean = re.sub('\\\\\\\\','',clean)\n",
    "    cleaned += [clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding Justices Present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(lst):\n",
    "    uni = []\n",
    "    for i in lst:\n",
    "        if i not in uni:\n",
    "            uni += [i]\n",
    "    return uni\n",
    "\n",
    "def case_no(txt):\n",
    "    return unique(re.findall('No.\\s\\d+[-]*\\d+',txt))\n",
    "\n",
    "for i in cleaned:\n",
    "    print(case_no(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def justices(texts):\n",
    "    d = {}\n",
    "    for txt in texts:\n",
    "        num = case_no(txt)[0]\n",
    "        j = re.findall('JUSTICE[A-Z\\s]+:',txt)\n",
    "        justice = sorted(unique(j))\n",
    "        cleaned_list = [justice[i][:-1] for i in range(len(justice))]\n",
    "        d[num] = cleaned_list\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Date, Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(text):\n",
    "    return re.findall('\\w+\\s+\\d+,\\s+\\d{4}',text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year(text):\n",
    "    return re.findall('\\d\\d\\d\\d',date(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This doesn't work\n",
    "def title(text):\n",
    "    s = re.findall('[-\\s]*[\\w\\n\\s\\d.,\\/#!$%\\^&\\*;:{}=\\-_`~()]*[-\\s]*',text)[0]\n",
    "    s1 = re.findall('\\w+\\s\\w+\\s\\w+',s)\n",
    "    first = re.findall('\\s\\w+',s1[0])\n",
    "    first = ''.join(first)\n",
    "    last = re.findall('\\s\\w+',s1[1])\n",
    "    last = ''.join(last)\n",
    "    title = first + ' v.'+last\n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Appearances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appearances(text):\n",
    "    app = re.findall('APPEARANCES:[\\s\\S]*?Reporting',text)[0]\n",
    "    app = re.findall('[\\s\\S]*?;[\\s\\S]*?\\.',app)\n",
    "    app = [re.sub('\\d','',app[i]) for i in range(len(app))]\n",
    "    remove_appearance = re.sub('APPEARANCES:\\s','',app[0])\n",
    "    app[0] = remove_appearance\n",
    "    app = [re.sub('[\\s\\s]+',' ',app[i]) for i in range(len(app))]\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAMES W. DABNEY, ESQ., New York, N.Y.; on behalf of Petitioner.\n",
      " THOMAS G. HUNGAR, ESQ., Deputy Solicitor General, Department of Justice, Washington, D.C.; on behalf of the United States, as amicus curiae, supporting Petitioner.\n",
      "-----------------------\n",
      "THEODORE B. OLSON, ESQ., Washington, D.C.; on behalf of Petitioner.\n",
      " DARYL JOSEFFER, ESQ., Assistant to the Solicitor General, Department of Justice, Washington, D.C.; On behalf of the United States, as amicus curiae, supporting Petitioner.\n",
      " SETH P. WAXMAN, ESQ., Washington, D.C.; on behalf of Respondent.\n",
      "-----------------------\n",
      "KEVIN K. RUSSELL, ESQ., Washington, D.C.; on behalf of the Petitioner.\n",
      " GLEN D. NAGER, ESQ., Washington, D.C.; on behalf of the Respondent.\n",
      " IRVING L. GORNSTEIN, ESQ., Assistant to the Solicitor General, Department of Justice, Washington, D.C.; as amicus curiae on behalf of the Respondent.\n",
      "-----------------------\n",
      "JAMES R. MILKEY, ESQ., Assistant Attorney General, Boston, Mass; on behalf of Petitioners.\n",
      " GREGORY C. GARRE, ESQ., Deputy Solicitor General, Department of Justice, Washington, D.C.; on behalf of Respondents.\n",
      "-----------------------\n",
      "CHARLES A. ROTHFELD, ESQ., Washington, D.C.; on behalf of the Petitioners.\n",
      " KAY H. HODGE, ESQ., Boston, Mass.; on behalf of the Respondents.\n",
      "-----------------------\n",
      "GLENN W. RHODES, ESQ., San Francisco, Cal.; on behalf of the Petitioner.\n",
      " THEODORE S. ALLISON, ESQ., Washington, D.C.; on behalf of the Respondents.\n",
      "-----------------------\n",
      "GREGORY S. COLEMAN, ESQ., Austin, Tex.; on behalf of the Appellant.\n",
      " NEAL K. KATYAL, ESQ., Deputy Solicitor General, Department of Justice, Washington, D.C.; on behalf of the Appellee Holder.\n",
      " DEBO P. ADEGBILE, ESQ., New York, N.Y.; on behalf of the Intervenor-Appellees.\n",
      "-----------------------\n",
      "WILLIAM J. YOUNG, ESQ., Springfield, Virginia; for Petitioners.\n",
      " JEREMIAH COLLINS, ESQ., Washington, D.C.; for Respondent.\n",
      "-----------------------\n",
      "SEAN R. GALLAGHER, ESQ., Denver, Colorado; for Petitioners.\n",
      " SRI SRINIVASAN, ESQ., Principal Deputy Solicitor General, Department of Justice, Washington, D.C.; for the United States, as amicus curiae, supporting Petitioners.\n",
      " DAVID A. LANE, ESQ., Denver, Colorado; for Respondent.\n",
      "-----------------------\n",
      "ERIC J. FEIGIN, ESQ., Assistant to the Solicitor General, Department of Justice, Washington, D.C.; on behalf of Petitioner.\n",
      " ROBERT S. HERTZBERG, ESQ., Southfield, Michigan; on behalf of Respondents.\n",
      "-----------------------\n",
      "CAROLYN E. SHAPIRO, ESQ., Solicitor General of Illinois, Chicago, Ill.; on behalf of Petitioner.\n",
      " BARRY LEVENSTAM, ESQ., Chicago, Ill.; on behalf of Respondent.\n",
      "-----------------------\n",
      "JEFFREY L. FISHER, ESQ., Stanford, California; on behalf of the Petitioners.\n",
      " ERIC J. FEIGIN, Assistant to the Solicitor General, Department of Justice, Washington, D.C.; on behalf of the Respondent.\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in cleaned:\n",
    "    app = appearances(i)\n",
    "    for j in app:\n",
    "        print(j)\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint 10/22**\n",
    "\n",
    "* need to work on finding the regex pattern between speakers\n",
    "* General pattern: \"SPEAKER: anything they say until the next SPEAKER:\"\n",
    "\n",
    "### STEPS:\n",
    "1. Extract the sentences from each speaker.\n",
    "2. Develop a function (actually there's one written in the github link below that you could model yours from; it's very good)\n",
    "3. Test it on various transcripts to ensure it's generalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note to Amal: Please look at these slides for performing sentiment analysis. They are from my IEOR class, and these techniques are very useful. Please let me know if you would like to go over it together.\n",
    "\n",
    "https://github.com/ikhlaqsidhu/data-x/blob/master/07a-tools-nlp-sentiment_add_missing_si/notebook-nlp-sentiment-analysis-imdb-afo_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I was trying to extract the speakers from each text. \n",
    "\n",
    "def dialogue(text):\n",
    "    sents = re.findall('[A-Z\\s]+:[\\s\\S]+?[A-Z]+?:',text) #regex pattern to find all instances\n",
    "    sents = [re.sub('\\d','',i) for i in sents] # cleaning transcript\n",
    "    sents = [re.sub('[\\s\\s]+',' ',i) for i in sents] #cleaning transcript\n",
    "    return sents\n",
    "\n",
    "other_regex_patters = re.findall('[A-Z\\s.]+:[\\s\\S]+?[A-Z\\s]+?:',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in re.findall('(MR. DABNEY:)([\\s\\S\\]+?)([A-Z][A-Z\\s]*:)',cleaned[0]):\n",
    "    print(i)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" CHIEF JUSTICE ROBERTS: We'll hear argument next in No. -, KSR International versus Teleflex, Incorporated. Mr. Dabney. ORAL ARGUMENT OF JAMES W. DABNEY ON BEHALF OF THE PETITIONER MR. DABNEY:\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue(cleaned[0])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building the DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Running functions over files\n",
    "\n",
    "cases = [case_no(i)[0] for i in cleaned]\n",
    "justice = [justices(cleaned).get(num) for num in cases]\n",
    "dates = [date(i) for i in cleaned]\n",
    "years = [year(i)[0] for i in cleaned]\n",
    "people = [appearances(i) for i in cleaned]\n",
    "title = [f for f in listdir('/home/jovyan/Liberating Archives Project') if isfile(join('/home/jovyan/Liberating Archives Project', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-45e66d251282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Case No'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Justices'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mjustice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Appearances'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeople\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/app/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/app/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/app/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/app/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7402\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'Title':title,'Case No': cases,'Justices':justice,'Date': dates,'Year':years,'Appearances':people})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2006-11-28\n",
       "1    2007-02-21\n",
       "2    2006-11-27\n",
       "3    2006-11-29\n",
       "4    2008-12-02\n",
       "5    2009-02-24\n",
       "6    2009-04-29\n",
       "7    2012-01-10\n",
       "8    2012-03-21\n",
       "9    2014-01-14\n",
       "10   2016-01-12\n",
       "11   2018-03-27\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
